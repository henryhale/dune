{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be294e28",
   "metadata": {},
   "source": [
    "# 2. Training\n",
    "In this section, the clean dataset is split into two sets:\n",
    "\n",
    "- training set\n",
    "- testing set\n",
    "\n",
    "The chosen model is trained on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clean_dataset_path = \"./data/dataset-clean.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(clean_dataset_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"[dataset]: file not found\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9340765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned text as the feature (input)\n",
    "X = df['clean_text'].fillna('')\n",
    "# label as the class (output)\n",
    "y = df['label']\n",
    "\n",
    "print(f\"Shape of features(X): {X.shape}\")\n",
    "print(f\"Shape of labels(X): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100e66a",
   "metadata": {},
   "source": [
    "### 2.1 Train-test split\n",
    "- The testing set should never be exposed to the model during training.\n",
    "- `stratify=y` is important for classification tasks to ensure that the proportion of classes is roughly the same in both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ae925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Size of training set: {len(X_train)}\")\n",
    "print(f\"Size of testing set: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f6b4d",
   "metadata": {},
   "source": [
    "### 2.2 Model selection\n",
    "To select the appropriate machine learning algorithms for text classification, several different approaches are tested and the best is taken.\n",
    "\n",
    "Since this is a classification problem, think \n",
    "- Naive Bayes\n",
    "- Tree-based algorithms(Random Forest, XGBoost, Decision Trees)\n",
    "- Logistic Regression.\n",
    "\n",
    "The input(feature) is text data, it has to be transformed to create a vector space mapping words to the likely output class. `scikit-learn` offers feature extraction techniques for text data(transforming text into numerical features)\n",
    "- TfidVectorizer\n",
    "- TfidTransformer\n",
    "\n",
    "There 2 approaches for this;\n",
    "- Manually or procedural flow - where we set up each step independently and connect the different tools together\n",
    "- Pipelines - automate the process by specifying the steps & order to take."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c8dd1a",
   "metadata": {},
   "source": [
    "#### 2.2.1 Selection\n",
    "The selected tools for the workflow are;\n",
    "- TfidVectorizer - transform text data into numerical features\n",
    "- Naive Bayes (MultinomialNB) - to classify several classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a168db",
   "metadata": {},
   "source": [
    "#### 2.2.2 Approach 1 - Manual setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb95f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# fit vectorizer to training set\n",
    "\n",
    "tfid = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "\n",
    "tfid.fit(X_train, y_train)\n",
    "\n",
    "tfid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# use vectorized data to fit naive bayes for multi-class prediction\n",
    "\n",
    "mnb = MultinomialNB(alpha=1.0)\n",
    "\n",
    "X_transformed = tfid.transform(X_train)\n",
    "y_transformed = tfid.transform(y_train)\n",
    "\n",
    "mnb.fit(X=X_transformed, y=y_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7406d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessing import preprocess_text\n",
    "\n",
    "def make_prediction(user_input):\n",
    "    clean_user_input = preprocess_text(user_input)\n",
    "\n",
    "    vectorized_input = tfid.transform([clean_user_input])\n",
    "\n",
    "    return mnb.predict(vectorized_input)\n",
    "\n",
    "# quick test\n",
    "\n",
    "user_prompt = \"what can you do?\"\n",
    "\n",
    "make_prediction(user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e48e0c0",
   "metadata": {},
   "source": [
    "#### 2.2.3 Approach 2 - Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e37939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline_mnb = Pipeline(\n",
    "    [\n",
    "        (\"tfdif\", TfidfVectorizer(ngram_range=(1, 2), max_features=5000)),\n",
    "        (\"clf\", MultinomialNB(alpha=1.0)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline_mnb.fit(X_train, y_train)\n",
    "\n",
    "pipeline_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df34c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessing import preprocess_text\n",
    "\n",
    "\n",
    "def make_prediction2(user_input):\n",
    "    clean_user_input = preprocess_text(user_input)\n",
    "\n",
    "    vectorized_input = tfid.transform([clean_user_input])\n",
    "\n",
    "    return mnb.predict(vectorized_input)\n",
    "\n",
    "\n",
    "# quick test\n",
    "\n",
    "user_prompt2 = \"select that item\"\n",
    "\n",
    "make_prediction2(user_prompt2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
